{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. random 함수를 위한 seed 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10b629870>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. training set과 Variable 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = [[73., 80., 75.],\n",
    "           [93., 88., 93.],\n",
    "           [89., 91., 90,],\n",
    "           [96., 98., 100.],\n",
    "           [73., 66., 70.]]\n",
    "y_train = [[152.],\n",
    "           [185.],\n",
    "           [180.],\n",
    "           [196.],\n",
    "           [142.]]\n",
    "\n",
    "X = Variable(torch.Tensor(x_train))\n",
    "Y = Variable(torch.Tensor(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. hypothesis, cost function, optimizer 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypothesis = nn.Linear(3, 1, bias=True)\n",
    "cost_func = nn.MSELoss()\n",
    "optimizer = optim.SGD(hypothesis.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model 훈련시키기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Error: [ 33198.97265625] Weight: [[ 0.4062224  -0.24209139 -0.18649648]] Bias: [ 0.10981031] \n",
      "Predicted: [[-10.70623875]\n",
      " [ -9.31228161]\n",
      " [-10.9783926 ]\n",
      " [-12.44423008]\n",
      " [ -5.79218197]]\n",
      "\n",
      "Step: 10000 Error: [ 0.24290702] Weight: [[ 1.06806338  0.45105794  0.49223495]] Bias: [ 0.11796333] \n",
      "Predicted: [[ 151.08883667]\n",
      " [ 184.91882324]\n",
      " [ 180.52302551]\n",
      " [ 196.07922363]\n",
      " [ 142.31288147]]\n",
      "\n",
      "Step: 20000 Error: [ 0.21093699] Weight: [[ 1.05775559  0.46512857  0.48852706]] Bias: [ 0.11826135] \n",
      "Predicted: [[ 151.18421936]\n",
      " [ 184.85385132]\n",
      " [ 180.55262756]\n",
      " [ 196.09809875]\n",
      " [ 142.22979736]]\n",
      "\n",
      "Step: 30000 Error: [ 0.19231209] Weight: [[ 1.05006194  0.47592172  0.4854691 ]] Bias: [ 0.11858411] \n",
      "Predicted: [[ 151.25701904]\n",
      " [ 184.80407715]\n",
      " [ 180.57519531]\n",
      " [ 196.11175537]\n",
      " [ 142.16677856]]\n",
      "\n",
      "Step: 40000 Error: [ 0.18146244] Weight: [[ 1.04438651  0.48418653  0.48291367]] Bias: [ 0.11895664] \n",
      "Predicted: [[ 151.31262207]\n",
      " [ 184.76629639]\n",
      " [ 180.59255981]\n",
      " [ 196.1217041 ]\n",
      " [ 142.1194458 ]]\n",
      "\n",
      "Step: 50000 Error: [ 0.17507227] Weight: [[ 1.04016352  0.49057341  0.48077679]] Bias: [ 0.11932917] \n",
      "Predicted: [[ 151.3553772 ]\n",
      " [ 184.73721313]\n",
      " [ 180.60595703]\n",
      " [ 196.12889099]\n",
      " [ 142.08348083]]\n",
      "\n",
      "Step: 60000 Error: [ 0.17128655] Weight: [[ 1.03704584  0.49551705  0.47897267]] Bias: [ 0.1197017] \n",
      "Predicted: [[ 151.38835144]\n",
      " [ 184.7149353 ]\n",
      " [ 180.61637878]\n",
      " [ 196.13404846]\n",
      " [ 142.05625916]]\n",
      "\n",
      "Step: 70000 Error: [ 0.16899526] Weight: [[ 1.03469348  0.49941915  0.47743949]] Bias: [ 0.12007423] \n",
      "Predicted: [[ 151.41418457]\n",
      " [ 184.69732666]\n",
      " [ 180.62449646]\n",
      " [ 196.13768005]\n",
      " [ 142.03512573]]\n",
      "\n",
      "Step: 80000 Error: [ 0.16768318] Weight: [[ 1.03328526  0.50230998  0.47597304]] Bias: [ 0.12044676] \n",
      "Predicted: [[ 151.43304443]\n",
      " [ 184.68475342]\n",
      " [ 180.63063049]\n",
      " [ 196.13952637]\n",
      " [ 142.02084351]]\n",
      "\n",
      "Step: 90000 Error: [ 0.166823] Weight: [[ 1.03209317  0.50469673  0.47478941]] Bias: [ 0.12081929] \n",
      "Predicted: [[ 151.44856262]\n",
      " [ 184.67420959]\n",
      " [ 180.63555908]\n",
      " [ 196.14099121]\n",
      " [ 142.00886536]]\n",
      "\n",
      "Step: 100000 Error: [ 0.16627449] Weight: [[ 1.03123617  0.50661314  0.47374097]] Bias: [ 0.12119181] \n",
      "Predicted: [[ 151.46105957]\n",
      " [ 184.66601562]\n",
      " [ 180.63967896]\n",
      " [ 196.14205933]\n",
      " [ 141.99977112]]\n",
      "\n",
      "Step: 110000 Error: [ 0.16595642] Weight: [[ 1.03117692  0.50786847  0.47255561]] Bias: [ 0.12156434] \n",
      "Predicted: [[ 151.46862793]\n",
      " [ 184.66110229]\n",
      " [ 180.64234924]\n",
      " [ 196.14122009]\n",
      " [ 141.99569702]]\n",
      "\n",
      "Step: 120000 Error: [ 0.16568133] Weight: [[ 1.03117692  0.50906056  0.47137463]] Bias: [ 0.12193687] \n",
      "Predicted: [[ 151.4757843 ]\n",
      " [ 184.65657043]\n",
      " [ 180.64491272]\n",
      " [ 196.14030457]\n",
      " [ 141.99206543]]\n",
      "\n",
      "Step: 130000 Error: [ 0.16547646] Weight: [[ 1.03117692  0.51004648  0.47039592]] Bias: [ 0.1223094] \n",
      "Predicted: [[ 151.48164368]\n",
      " [ 184.65267944]\n",
      " [ 180.64691162]\n",
      " [ 196.13943481]\n",
      " [ 141.98901367]]\n",
      "\n",
      "Step: 140000 Error: [ 0.16533494] Weight: [[ 1.03117692  0.51082379  0.46962312]] Bias: [ 0.12268193] \n",
      "Predicted: [[ 151.48623657]\n",
      " [ 184.64958191]\n",
      " [ 180.64846802]\n",
      " [ 196.13870239]\n",
      " [ 141.98658752]]\n",
      "\n",
      "Step: 150000 Error: [ 0.16523579] Weight: [[ 1.03117692  0.51142222  0.46902707]] Bias: [ 0.12305446] \n",
      "Predicted: [[ 151.48977661]\n",
      " [ 184.64717102]\n",
      " [ 180.6496582 ]\n",
      " [ 196.1381073 ]\n",
      " [ 141.98472595]]\n",
      "\n",
      "Step: 160000 Error: [ 0.16513947] Weight: [[ 1.03117692  0.51201934  0.46843287]] Bias: [ 0.12342699] \n",
      "Predicted: [[ 151.49336243]\n",
      " [ 184.64485168]\n",
      " [ 180.65089417]\n",
      " [ 196.1375885 ]\n",
      " [ 141.98292542]]\n",
      "\n",
      "Step: 170000 Error: [ 0.1650589] Weight: [[ 1.03117692  0.51261538  0.46784022]] Bias: [ 0.12379952] \n",
      "Predicted: [[ 151.4969635 ]\n",
      " [ 184.64253235]\n",
      " [ 180.65216064]\n",
      " [ 196.13710022]\n",
      " [ 141.98114014]]\n",
      "\n",
      "Step: 180000 Error: [ 0.16498829] Weight: [[ 1.031178    0.51321143  0.46724659]] Bias: [ 0.12417205] \n",
      "Predicted: [[ 151.50057983]\n",
      " [ 184.64025879]\n",
      " [ 180.65345764]\n",
      " [ 196.13665771]\n",
      " [ 141.97938538]]\n",
      "\n",
      "Step: 190000 Error: [ 0.16492048] Weight: [[ 1.03121614  0.51377302  0.46665055]] Bias: [ 0.12454458] \n",
      "Predicted: [[ 151.50393677]\n",
      " [ 184.63815308]\n",
      " [ 180.65466309]\n",
      " [ 196.13607788]\n",
      " [ 141.97787476]]\n",
      "\n",
      "Step: 200000 Error: [ 0.16485165] Weight: [[ 1.0315963   0.51399142  0.4660545 ]] Bias: [ 0.1249171] \n",
      "Predicted: [[ 151.50485229]\n",
      " [ 184.63769531]\n",
      " [ 180.65513611]\n",
      " [ 196.13478088]\n",
      " [ 141.97871399]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in range(200001):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    Y_hat = hypothesis(X)\n",
    "    cost = cost_func(Y_hat, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 10000 == 0:\n",
    "        print(\"Step:\", step, \n",
    "              \"Error:\", cost.data.numpy(), \n",
    "              \"Weight:\", hypothesis.weight.data.numpy(),\n",
    "              \"Bias:\", hypothesis.bias.data.numpy(),\n",
    "              \"\\nPredicted:\", Y_hat.data.numpy())\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
