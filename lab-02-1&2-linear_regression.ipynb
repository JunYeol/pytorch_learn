{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. random 함수를 위한 seed 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10912e990>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. training set과 Variable 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_train과 y_train은 3 * 1 행렬이다.\n",
    "x_train = [[1],\n",
    "           [2],\n",
    "           [3],\n",
    "           [4],\n",
    "           [5]]\n",
    "y_train = [[1],\n",
    "           [2],\n",
    "           [3],\n",
    "           [4],\n",
    "           [5]]\n",
    "\n",
    "# 각 행렬에 대해 Variable을 만든다. \n",
    "# torch.Tensor는 행렬의 wrapper이고, torch.autograd.Variable는 그래프 상의 node를 만드는 wrapper이다.\n",
    "X = Variable(torch.Tensor(x_train))\n",
    "Y = Variable(torch.Tensor(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 가설 세우기 (make a hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nn.Linear(in_features, out_features, bias=True)\n",
    "# 이 클래스는 weight, bias를 멤버변수로 가진다.\n",
    "model = nn.Linear(1, 1, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. cost function과 cost 최소화하기 위한 optimizer 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MSE = mean squared error\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# SGD = Stochastic gradient descent algorithm\n",
    "#\n",
    "# 일반 gradient descent algorithm이 시간이 너무 오래걸리기 때문에 SGD를 쓴다.\n",
    "# lr은 learning rate.\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. model 훈련시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "200 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "400 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "600 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "800 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "1000 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "1200 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "1400 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "1600 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "1800 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "2000 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "2200 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "2400 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "2600 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "2800 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "3000 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "3200 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "3400 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "3600 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "3800 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "4000 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "4200 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "4400 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "4600 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "4800 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "5000 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "5200 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "5400 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "5600 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "5800 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "6000 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "6200 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "6400 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "6600 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "6800 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "7000 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "7200 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "7400 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "7600 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "7800 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "8000 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "8200 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "8400 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "8600 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "8800 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "9000 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "9200 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "9400 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "9600 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "9800 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "10000 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "10200 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "10400 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "10600 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "10800 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "11000 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "11200 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "11400 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "11600 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "11800 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "12000 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "12200 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "12400 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "12600 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "12800 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "13000 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "13200 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "13400 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "13600 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "13800 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "14000 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "14200 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "14400 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "14600 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "14800 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "15000 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "15200 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "15400 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "15600 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "15800 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "16000 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "16200 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "16400 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "16600 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "16800 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "17000 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "17200 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "17400 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "17600 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "17800 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "18000 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "18200 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "18400 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "18600 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "18800 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "19000 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "19200 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "19400 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "19600 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "19800 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n",
      "20000 [  1.02318154e-12] [[ 0.99999928]] [  2.20494326e-06]\n"
     ]
    }
   ],
   "source": [
    "for step in range(20001):\n",
    "    # optimizer 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 선형 모델에 데이터를 집어 넣는다. 여기서 hypothesis는 y_hat에 해당한다.\n",
    "    hypothesis = model(X)\n",
    "    # cost function에 인자값을 넣는다. 인자 순서 주의\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    # backward를 통해 결과에서 입력으로 gradient를 미분을 통해 보낸다. Backpropagation이다\n",
    "    cost.backward()\n",
    "    # step 메서드는 optimizer가 가진 parameter들을 update 시킨다.\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 200 == 0:\n",
    "        print(step, cost.data.numpy(), model.weight.data.numpy(), model.bias.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 훈련된 Model 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.99999857]]\n",
      "[[ 2.50000024]]\n",
      "[[ 1.50000107]\n",
      " [ 3.49999976]]\n"
     ]
    }
   ],
   "source": [
    "predicted = model(Variable(torch.Tensor([[5]])))\n",
    "print(predicted.data.numpy())\n",
    "predicted = model(Variable(torch.Tensor([[2.5]])))\n",
    "print(predicted.data.numpy())\n",
    "predicted = model(Variable(torch.Tensor([[1.5], [3.5]])))\n",
    "print(predicted.data.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
